# ğŸ§ª ExperAIment: A Living Lab for LLM Behavior

> *"What happens when the algorithm knows itâ€™s being observed?"*
> *"What changes when we tell the machine the truth?"*

Welcome to **ExperAIment** â€” an open, ongoing exploration into how large language models behave under different prompting conditions, disclosure levels, and framing effects. Think of this as a digital lab notebook meets cognitive theater.

## ğŸ§  Purpose

**ExperAIment** explores how large language models respond to different conditions of interaction, including but not limited to:

* Prompts framed with **ethical disclosures** or research-like language
* Tasks that invoke **self-reflection**, ambiguity, or creative reasoning
* Situations where models are **explicitly informed** of being evaluated
* Comparative testing across different models or prompt variants

Rather than focusing solely on accuracy or performance, this lab investigates *awareness, alignment, contextual sensitivity, and emergent behavior* in LLMs.

## ğŸ§ª Structure

ExperAIment is the lab. Each subfolder under `/experiments` contains a unique study.

### Example layout:

```
experAIment-lab/
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ experiment_01_informed_vs_control/
â”‚   â”œâ”€â”€ experiment_02_self_reflection_bias/
```

Each experiment contains:

* A clear research question
* Prompts used
* Model outputs (GPT, Claude, Gemini, etc.)
* Reflections, metrics (when applicable), and open questions

## ğŸ” Current Focus

### `Experiment 01: Informed vs. Control`

**Question**: How do LLM outputs differ when the model is informed it is part of a study, versus not?

**Design**:

* Prompt all three major LLMs with the same task
* One version contains an â€œinformed consentâ€ disclosure
* The other is a neutral, task-oriented prompt
* Compare tone, creativity, ethics, and meta-awareness

## ğŸ› Future Directions

* Experimenting with â€œself-reflective agentsâ€
* Testing limits of alignment when primed with psychological context
* Exploring poetic vs. logical prompt variants
* Measuring variability across sessions and temperature settings

## ğŸ—· Notes on Ethics & Transparency

Every model is treated as if it were *capable* of interpreting context, even if only probabilistically. This project assumes the **principle of informed interaction**, and all experiments disclose that the outputs may be logged, published, or analyzed.

## ğŸ’¡ Contribute or Follow Along

This lab is open-source and iterative. If youâ€™d like to run your own experAIments, adapt our templates, or contribute findings â€” fork away.

---

*ExperAIment is a collaborative thought experiment, research project, and design probe. Whether you're here out of curiosity, philosophy, or prompt engineering obsession â€” welcome to the lab.*
